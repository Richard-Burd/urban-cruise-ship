import SolutionDropdown from '/components/SolutionDropdown.js'

export const problem = "Risk From Artificial Intelligence";
export const solution = "Explainable AI";

Artifical intelligence, while a powerful technology, is potentially dangerous if misused or abused. Even before full artificial general intelligence is developed, cybercrime and algorithmic biases are serious and growing issue.

Machine learning, which seeks to develop patterns from data, is the predominant current method of artificial intelligence. Such systems can fail or behave in unexpected ways when they encounter scenarios different from the data on which they were trained. One approach to reducing the risk under these circumstances is interpretability, or explanability, which requires that a machine learning system provide reasons for the decisions that it makes [^"17"]. Regulation from the European Union requires that an AI system is explainable, and relatedly transparent, under some situations such as when the system is used by doctor, lawyers, or environmentalists [^"1"].

[^"1"]: Bar, G. ["Explainability as a legal requirement for Artificial Intelligence"](https://medium.com/womeninai/explainability-as-a-legal-requirement-for-artificial-intelligence-systems-66da5a0aa693). WomeninAI. Novebmer 2020.

[^"17"]: Rudner, T. G. J., Toner, H. ["Key Concepts in AI Safety: An Overview"](https://cset.georgetown.edu/publication/key-concepts-in-ai-safety-an-overview/). Center for Security and Emerging Technology. March 2021.

export default ({ children }) => 
  <SolutionDropdown 
    problem={problem} 
    solution={solution}
  >
    {children}
  </SolutionDropdown>